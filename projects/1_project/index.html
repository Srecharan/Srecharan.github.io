<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Hybrid CV-ML Approach for Autonomous Leaf Grasping | Srecharan Selvam </title> <meta name="author" content="Srecharan Selvam"> <meta name="description" content="A novel vision system combining geometric computer vision with deep learning for leaf detection and grasp point optimization"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?29f7cbda2ac1020cfcef4c86b03c404d"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://srecharan.github.io/projects/1_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Srecharan Selvam </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">Projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link"><i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Hybrid CV-ML Approach for Autonomous Leaf Grasping</h1> <p class="post-description">A novel vision system combining geometric computer vision with deep learning for leaf detection and grasp point optimization</p> </header> <article> <h3 id="overview">Overview</h3> <p>A real-time vision system for leaf manipulation combining geometric computer vision techniques with deep learning. This hybrid system integrates YOLOv8 for leaf segmentation, RAFT-Stereo for depth estimation, and a custom CNN (GraspPointCNN) for grasp point optimization. The architecture features self-supervised learning that eliminates manual annotation, and a confidence-weighted decision framework that dynamically balances traditional CV algorithms with CNN predictions to achieve superior grasping performance.</p> <div style="text-align: center;"> <img src="/assets/img/REX.drawio_f.png" alt="System Architecture" style="width: 100%; max-width: 800px;"> <p><em>Multi-stage perception pipeline integrating traditional computer vision with deep learning</em></p> </div> <h3 id="multi-stage-perception-pipeline">Multi-Stage Perception Pipeline</h3> <p>The system employs a three-stage perception pipeline:</p> <ol> <li> <p><strong>Instance Segmentation (YOLOv8)</strong>: Fine-tuned on a custom dataset of ~900 images, achieving 68% mAP@[0.5:0.95] for leaf mask generation</p> </li> <li> <p><strong>Depth Estimation (RAFT-Stereo)</strong>: High-precision depth maps with sub-pixel accuracy (&lt;0.5px) from stereo pairs, enabling detailed 3D reconstruction</p> </li> <li> <p><strong>Hybrid Grasp Point Selection</strong>: Combines geometric CV with machine learning refinement</p> </li> </ol> <div style="text-align: center;"> <img src="/assets/img/pcd.gif" alt="3D Point Cloud" style="width: 100%; max-width: 800px;"> <p><em>Complete stereo vision pipeline: RGB stereo input, disparity map generation, and resulting 3D point cloud reconstruction</em></p> </div> <h3 id="traditional-computer-vision-pipeline">Traditional Computer Vision Pipeline</h3> <p>The geometric CV component uses Pareto optimization for leaf selection based on:</p> <ul> <li> <strong>Clutter Score (35%)</strong>: Isolation from other leaves using Signed Distance Fields</li> <li> <strong>Distance Score (35%)</strong>: Proximity to camera with exponential falloff</li> <li> <strong>Visibility Score (30%)</strong>: Completeness of view and position in frame</li> </ul> <p>Grasp point selection employs weighted scoring criteria:</p> <ul> <li> <strong>Flatness Analysis (25%)</strong>: Surface smoothness using depth gradients</li> <li> <strong>Approach Vector Quality (40%)</strong>: Optimal approach direction</li> <li> <strong>Accessibility (15%)</strong>: Position relative to camera</li> <li> <strong>Edge Awareness (20%)</strong>: Distance from leaf boundaries</li> </ul> <div style="text-align: center;"> <img src="/assets/img/cv_output.png" alt="Traditional CV Output" style="width: 100%; max-width: 800px;"> <p><em>Traditional CV pipeline output: Segmented leaf visualization with grasp point selection (left), and raw stereo camera image with detected leaf midrib (right)</em></p> </div> <h3 id="ml-enhanced-decision-making">ML-Enhanced Decision Making</h3> <p>The machine learning component features a custom CNN architecture (GraspPointCNN) with:</p> <ul> <li> <strong>Self-Supervised Learning</strong>: CV pipeline acts as an expert teacher</li> <li> <strong>Data Collection</strong>: Automated generation of positive/negative samples</li> <li> <strong>9-Channel Input Features</strong>: Depth map, binary mask, and 7 score maps</li> <li> <strong>Attention Mechanism</strong>: Enables focus on most relevant patch regions</li> </ul> <div style="text-align: center;"> <img src="/assets/img/CNN_grasp.drawio.png" alt="CNN Architecture" style="width: 100%; max-width: 800px;"> <p><em>GraspPointCNN architecture: A 9-channel input feature map processed through three encoder blocks with an attention mechanism, followed by dense layers and global average pooling</em></p> </div> <h3 id="hybrid-decision-integration">Hybrid Decision Integration</h3> <p>The system implements a dynamic integration strategy:</p> <ul> <li>Traditional CV generates candidate grasp points</li> <li>ML model evaluates candidates with confidence scores</li> <li>Weighted average combines both approaches: <div class="language-python highlighter-rouge"> <div class="highlight"><pre class="highlight"><code><span class="n">ml_conf</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="nf">abs</span><span class="p">(</span><span class="n">ml_score</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
<span class="n">ml_weight</span> <span class="o">=</span> <span class="nf">min</span><span class="p">(</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">ml_conf</span> <span class="o">*</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="n">final_score</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">ml_weight</span><span class="p">)</span> <span class="o">*</span> <span class="n">trad_score</span> <span class="o">+</span> <span class="n">ml_weight</span> <span class="o">*</span> <span class="n">ml_score</span>
</code></pre></div> </div> </li> <li>ML influence varies (10-30%) based on prediction confidence</li> <li>Falls back to traditional CV (70-90%) for low-confidence predictions</li> </ul> <div style="text-align: center;"> <img src="/assets/img/rex_grasp.gif" alt="System Operation" style="width: 100%; max-width: 800px;"> <p><em>Complete pipeline in action: perception, planning, and execution</em></p> </div> <h3 id="results--performance">Results &amp; Performance</h3> <h4 id="model-metrics">Model Metrics</h4> <table> <thead> <tr> <th>Metric</th> <th>Value</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td>Validation Accuracy</td> <td>93.14%</td> <td>Overall model accuracy</td> </tr> <tr> <td>Positive Accuracy</td> <td>97.09%</td> <td>Accuracy for successful grasp points</td> </tr> <tr> <td>Precision</td> <td>92.59%</td> <td>True positives / predicted positives</td> </tr> <tr> <td>Recall</td> <td>97.09%</td> <td>True positives / actual positives</td> </tr> <tr> <td>F1 Score</td> <td>94.79%</td> <td>Balanced measure of precision and recall</td> </tr> </tbody> </table> <h4 id="system-performance-150-test-cases">System Performance (150 test cases)</h4> <table> <thead> <tr> <th>Metric</th> <th>Classical CV</th> <th>Hybrid (CV+ML)</th> <th>Improvement</th> </tr> </thead> <tbody> <tr> <td>Accuracy (px)</td> <td>25.3</td> <td>27.1</td> <td>+1.8</td> </tr> <tr> <td>Feature Alignment (%)</td> <td>80.67</td> <td>83.33</td> <td>+2.66</td> </tr> <tr> <td>Edge Case Handling (%)</td> <td>75.33</td> <td>77.33</td> <td>+2.00</td> </tr> <tr> <td>Overall Success Rate (%)</td> <td>78.00</td> <td>82.66</td> <td>+4.66</td> </tr> </tbody> </table> <div style="text-align: center;"> <img src="/assets/img/training_metrics.png" alt="Training Metrics" style="width: 100%; max-width: 800px;"> <p><em>Training curves showing loss convergence and accuracy metrics over training epochs</em></p> </div> <h3 id="key-innovations">Key Innovations</h3> <ul> <li> <strong>Hybrid CV-ML Architecture</strong>: Combines the reliability of geometric reasoning with the adaptability of deep learning</li> <li> <strong>Self-Supervised Learning</strong>: CV pipeline acts as an expert teacher, eliminating manual data annotation</li> <li> <strong>Dynamic Integration Strategy</strong>: Confidence-based weighting balances traditional CV with ML predictions</li> <li> <strong>Real-Time Performance</strong>: Full pipeline operates with ~150ms latency on consumer GPU hardware</li> <li> <strong>Attention Mechanism</strong>: CNN design with focused feature extraction for improved prediction accuracy</li> </ul> <h3 id="technologies-used">Technologies Used</h3> <ul> <li> <strong>Languages</strong>: Python, C++</li> <li> <strong>Frameworks</strong>: PyTorch, CUDA, OpenCV, Scikit-learn, Numpy, Pandas, Matplotlib</li> <li> <strong>Computer Vision</strong>: Instance Segmentation, Depth Estimation, Point Cloud Processing, SDF, 3D Perception</li> <li> <strong>Deep Learning</strong>: CNN Architecture Design, Self-Supervised Learning, Model Training &amp; Optimization, Attention Mechanisms</li> <li> <strong>Cloud Computing</strong>: AWS EC2</li> </ul> <h3 id="resources">Resources</h3> <ul> <li><a href="https://github.com/Srecharan/LeafGrasp-Vision-ML" rel="external nofollow noopener" target="_blank">GitHub Repository</a></li> <li><a href="https://github.com/Srecharan/YoloV8Seg-REX.git" rel="external nofollow noopener" target="_blank">YOLOv8 Segmentation Node</a></li> <li><a href="https://github.com/Srecharan/RAFTStereo-REX.git" rel="external nofollow noopener" target="_blank">RAFT-Stereo Node</a></li> </ul> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Srecharan Selvam. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-projects",title:"Projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-publications",title:"Publications",description:"",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-repositories",title:"Repositories",description:"",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-hybrid-cv-ml-approach-for-autonomous-leaf-grasping",title:"Hybrid CV-ML Approach for Autonomous Leaf Grasping",description:"A novel vision system combining geometric computer vision with deep learning for leaf detection and grasp point optimization",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-optimization-based-control-and-estimation-in-compliant-robotic-systems",title:"Optimization-Based Control and Estimation in Compliant Robotic Systems",description:"",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-linear-friction-welding-lfw-of-nickel-aluminium-bronze-nab-joints",title:"Linear Friction Welding (LFW) of Nickel Aluminium Bronze (NAB) Joints",description:"",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-enhancing-corrosion-resistance-of-magnesium-alloy-microtubes-via-micro-arc-oxidation",title:"Enhancing Corrosion Resistance of Magnesium Alloy Microtubes via Micro-Arc Oxidation",description:"",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%73%73%65%6C%76%61%6D@%61%6E%64%72%65%77.%63%6D%75.%65%64%75","_blank")}},{id:"socials-whatsapp",title:"WhatsApp",section:"Socials",handler:()=>{window.open("https://wa.me/19174953410","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=Srecharan Selvam","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/Srecharan","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/srecharan@gmail.com","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>